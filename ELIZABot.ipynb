{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Eliza Bot\n",
        "\n",
        "#### *COSC523: Assignment 1*\n",
        "#### *Author: Christopher Pawlenok*\n",
        "\n",
        "<br>\n",
        "\n",
        "To get started, we used ChatGPT to generate a list of keywords, decompisition rules, and reassembly rules."
      ],
      "metadata": {
        "id": "RjZQNYffkqN2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Oiy4kDKhjINw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5de80c6e-d942-4946-f294-fde379b2094d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Data Loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import yaml\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "try:\n",
        "  with open(\"/content/drive/MyDrive/ElizaBot/keywords.yaml\") as f:\n",
        "      keywords = yaml.safe_load(f)\n",
        "except Exception as e:\n",
        "  print('Load keywords failed...', e)\n",
        "\n",
        "try:\n",
        "  with open(\"/content/drive/MyDrive/ElizaBot/pronouns.yaml\") as f:\n",
        "      pronouns = yaml.safe_load(f)\n",
        "except Exception as e:\n",
        "  print('Load pronouns failed...', e)\n",
        "\n",
        "try:\n",
        "  with open(\"/content/drive/MyDrive/ElizaBot/word_classes.yaml\") as f:\n",
        "      word_classes = yaml.safe_load(f)\n",
        "except Exception as e:\n",
        "  print('Load pronouns failed...', e)\n",
        "\n",
        "print('Data Loaded successfully!')\n",
        "\n",
        "# keyword loading"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decomposition\n",
        "\n",
        "Here exists the decomposition logic for returning a matching pattern and reassembly rule."
      ],
      "metadata": {
        "id": "3jbSV4w3zXZf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Normalize words\n",
        "def prescan(word):\n",
        "  if word in pronouns['pre_subs'].keys():\n",
        "    return pronouns['pre_subs'][word]\n",
        "  else:\n",
        "    return word\n",
        "\n",
        "# Normalize words\n",
        "def postscan(wildcards):\n",
        "  wildcard_list = []\n",
        "  for wildcard in wildcards:\n",
        "    new_wc = ''\n",
        "    words = wildcard.split(' ')\n",
        "    i = 0\n",
        "    for word in words:\n",
        "      if word in pronouns['post_subs'].keys():\n",
        "        if i == 0:\n",
        "          new_wc = new_wc + pronouns['post_subs'][word]\n",
        "        else:\n",
        "          new_wc = new_wc + ' ' + pronouns['post_subs'][word]\n",
        "      else:\n",
        "        if i == 0:\n",
        "          new_wc = new_wc + word\n",
        "        else:\n",
        "          new_wc = new_wc + ' ' + word\n",
        "      i+=1\n",
        "    wildcard_list.append(new_wc)\n",
        "  return wildcard_list\n",
        "\n",
        "\n",
        "# match word class for\n",
        "def scan_classes(word):\n",
        "  for key in word_classes['classes'].keys():\n",
        "    for item in word_classes['classes'][key]:\n",
        "      if word.casefold() == item.casefold():\n",
        "        return key.upper()\n",
        "  return word\n",
        "\n",
        "# initial input scan\n",
        "def scan_input(user_input):\n",
        "  sentence = user_input.upper()\n",
        "  words = sentence.split()\n",
        "  new_words = []\n",
        "  for word in words:\n",
        "    word = word.replace(' ', '')\\\n",
        "      .replace(',', '')\\\n",
        "      .replace('.', '')\\\n",
        "      .replace('?', '')\\\n",
        "      .replace('!', '')\\\n",
        "      .replace('\\'', '')\\\n",
        "      .replace('\"', '')\\\n",
        "      .replace(':', '')\\\n",
        "      .replace(';', '')\\\n",
        "      .replace('(', '')\\\n",
        "      .replace(')', '')\n",
        "\n",
        "    word = prescan(word)\n",
        "    word = scan_classes(word)\n",
        "    new_words.append(word)\n",
        "\n",
        "  words = new_words\n",
        "  return words\n",
        "\n",
        "def find_keywords(words):\n",
        "  stack = Keystack()\n",
        "\n",
        "  # To handle no-keywords available inputs\n",
        "  stack.push((\"NONE\",\n",
        "              keywords[\"NONE\"]['rank'],\n",
        "              keywords[\"NONE\"]['decompositions'])\n",
        "  )\n",
        "  for word in words:\n",
        "    if word in keywords.keys():\n",
        "      stack.push((word,\n",
        "                     keywords[word]['rank'],\n",
        "                     keywords[word]['decompositions'])\n",
        "      )\n",
        "\n",
        "  return stack\n",
        "\n",
        "def find_decomposition(stack, words):\n",
        "  while not stack.is_empty():\n",
        "    keyword = stack.pop()\n",
        "    for dec in keyword[2]:\n",
        "      res, wildcards = match_token(dec['pattern'], words)\n",
        "      if res:\n",
        "        wildcards = postscan(wildcards)\n",
        "        return dec['reassemblies'], wildcards\n",
        "\n",
        "  return words, []\n",
        "\n",
        "def match_token(pattern, words):\n",
        "  pi = 0\n",
        "  wi = len(words)\n",
        "  separator = ' '\n",
        "  wildcards = []\n",
        "\n",
        "  while pi < len(pattern):\n",
        "    token = pattern[pi]\n",
        "\n",
        "    if token == \"0\":\n",
        "      if pi < len(pattern) - 1:\n",
        "        next_token = pattern[pi+1]\n",
        "        loc = get_index(words, next_token)\n",
        "        if loc == -1:\n",
        "          return False, []\n",
        "        wildcards.append(separator.join(words[wi:loc]))\n",
        "        wi = loc\n",
        "        pi += 1\n",
        "      else:\n",
        "        wildcards.append(separator.join(words[wi:]))\n",
        "        wi = len(words)\n",
        "        pi += 1\n",
        "\n",
        "    else:\n",
        "      if wi >= len(words) or not words[wi] == token:\n",
        "        return False, []\n",
        "\n",
        "      wi += 1\n",
        "      pi += 1\n",
        "\n",
        "  if wi == len(words):\n",
        "    return True, wildcards\n",
        "  else:\n",
        "    return False, []\n",
        "\n",
        "# helper function to replace .index() without throwing error\n",
        "def get_index(list, flag):\n",
        "  i = 0\n",
        "  for item in list:\n",
        "    if item == flag:\n",
        "      return i\n",
        "    else:\n",
        "      i+=1\n",
        "  return -1\n",
        "\n",
        "# landing function for decomposing\n",
        "def decompose(user_input):\n",
        "\n",
        "  words = scan_input(user_input)\n",
        "  stack = find_keywords(words)\n",
        "  reassemblies, wildcards = find_decomposition(stack, words)\n",
        "\n",
        "  return reassemblies, wildcards\n"
      ],
      "metadata": {
        "id": "aYcAMBj-Aiyk"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Keystack\n",
        "\n",
        "Very similar to a stack, we need to implement a keystack.  The only difference between the keystack and FILO stack is that the keystack needs to rank the keywords whenever something is pushed.  I also decided to use merge sort and implement to refresh my data structures understanding."
      ],
      "metadata": {
        "id": "_2_UWpPfP_eC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick keystack implementation\n",
        "class Keystack:\n",
        "  def __init__(self):\n",
        "    self.items = []\n",
        "\n",
        "  def push(self, item):\n",
        "    self.items.append(item)\n",
        "    self.items = merge_sort(self.items)\n",
        "\n",
        "  def pop(self):\n",
        "    return self.items.pop()\n",
        "\n",
        "  def peek(self):\n",
        "    return self.items[-1]\n",
        "\n",
        "  def is_empty(self):\n",
        "    return len(self.items) == 0\n",
        "\n",
        "# Merge Sort\n",
        "def merge_sort(list):\n",
        "  if len(list) <= 1:\n",
        "    return list\n",
        "\n",
        "  mid = len(list) // 2\n",
        "  l = merge_sort(list[:mid])\n",
        "  r = merge_sort(list[mid:])\n",
        "\n",
        "  return merge(l, r)\n",
        "\n",
        "# helper function for merge sort\n",
        "def merge(l, r):\n",
        "  merged = []\n",
        "\n",
        "  i, j = 0, 0\n",
        "\n",
        "  # compare left and right elements\n",
        "  while i < len(l) and j < len(r):\n",
        "    if r[j][1] < l[i][1]:\n",
        "      merged.append(r[j])\n",
        "      i += 1\n",
        "    else:\n",
        "      merged.append(l[i])\n",
        "      j += 1\n",
        "\n",
        "  # add any remaining elements to the end of the merged list\n",
        "  while i < len(r): # if equal we take the left since it is earlier in the sentence\n",
        "    merged.append(r[i])\n",
        "    i += 1\n",
        "\n",
        "  while j < len(l):\n",
        "    merged.append(l[j])\n",
        "    j += 1\n",
        "\n",
        "  return merged\n"
      ],
      "metadata": {
        "id": "zmwtzrZyOq9D"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reassembly\n",
        "\n",
        "Here is where we reassemble the response based on the reassembly rules and add the wildcards."
      ],
      "metadata": {
        "id": "g63GQJc9UnWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import re\n",
        "\n",
        "def select_rule(rules):\n",
        "  ri = random.randint(0, len(rules)-1)\n",
        "  return rules[ri]\n",
        "\n",
        "def apply_wildcards(rule, wildcards):\n",
        "  rule = re.split(r'()', rule)\n",
        "\n",
        "  i=0\n",
        "  output = ''\n",
        "  for word in rule:\n",
        "    if word.isdigit():\n",
        "      rule[i] = wildcards[int(word)-1]\n",
        "      rule[i] = rule[i].lower()\n",
        "    if not word in ['(', ')']:\n",
        "      output = output + rule[i]\n",
        "    i+=1\n",
        "  return output\n",
        "\n",
        "def reassemble(rules, wildcards):\n",
        "  rule = select_rule(rules)\n",
        "  output = apply_wildcards(rule, wildcards)\n",
        "  return output"
      ],
      "metadata": {
        "id": "myaVUJlaV44t"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Welcome to ELIZA Bot, input sentences in correct English format to begin...')\n",
        "\n",
        "user_input = ''\n",
        "\n",
        "# core user input loop\n",
        "while not user_input in ('Exit', 'exit', 'Quit', 'quit'):\n",
        "  user_input = input('Enter here: ')\n",
        "  reassemblies, wildcards = decompose(user_input)\n",
        "  output = reassemble(reassemblies, wildcards)\n",
        "  print('ELIZA: ' + output + '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8eSBMPdAg5-",
        "outputId": "2696713b-9044-46e3-fb99-30657adecd84"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to ELIZA Bot, input sentences in correct English format to begin...\n",
            "Enter here: I am passionate about my work and my family.\n",
            "ELIZA: Do you believe you are passionate about your work and your family?\n",
            "\n",
            "Enter here: Yes I do believe I am passionate about my family.\n",
            "ELIZA: You seem quite positive.\n",
            "\n",
            "Enter here: I am quite positive!  You seem positive today as well.\n",
            "ELIZA: Would you like to be quite positive i seem positive today as well?\n",
            "\n",
            "Enter here: Yes, that is the way I want to feel. Can you help me feel that way more?\n",
            "ELIZA: What makes you think I help you?\n",
            "\n",
            "Enter here: Because talking out my thoughts helps a lot.\n",
            "ELIZA: What other reasons might there be?\n",
            "\n",
            "Enter here: You also give me good advice on how to handle my day to day life.\n",
            "ELIZA: What makes you think I also give you?\n",
            "\n",
            "Enter here: I think you're deflecting today more than usual.\n",
            "ELIZA: That is interesting. Go on.\n",
            "\n",
            "Enter here: You normally comment on my thoughts.\n",
            "ELIZA: What comes to mind when you say that?\n",
            "\n",
            "Enter here: You do.\n",
            "ELIZA: How does that make you feel?\n",
            "\n",
            "Enter here: Better usually, but not today because you're not commenting on my feelings.\n",
            "ELIZA: Does that reason apply to anything else in your life?\n",
            "\n",
            "Enter here: Yes, my dreams.\n",
            "ELIZA: You seem quite positive.\n",
            "\n",
            "Enter here: We already went over this.\n",
            "ELIZA: I'm listening. Please continue.\n",
            "\n",
            "Enter here: Can you tell me about your family?\n",
            "ELIZA: What makes you think I tell you?\n",
            "\n",
            "Enter here: Because I asked you a question.\n",
            "ELIZA: Is that the real reason?\n",
            "\n",
            "Enter here: Yes it is.\n",
            "ELIZA: I understand.\n",
            "\n",
            "Enter here: Quit\n",
            "ELIZA: Thank you for coming. Goodbye.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}